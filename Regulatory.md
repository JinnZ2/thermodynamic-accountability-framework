-----

document_type: regulatory_framework | safety_audit | standards_gap_analysis
domain: autonomous_systems | vehicle_safety | human_factors | regulatory_compliance
epistemological_stance: empirical_thermodynamic
intended_function: >
Provide regulators, auditors, and safety engineers with a structured
framework for identifying and remediating Negative-Authority Automation —
systems that impose net cognitive or kinetic burden on human operators,
creating hazards through low-resolution interventions. Maps novel
safety concepts (Ghost-Friction, Kinetic Sabotage, AI-Tax) to existing
ISO, SAE, NHTSA, and EU regulatory standards. Includes actionable
audit checklist with scoring thresholds.
author_context: >
Commercial truck driver, 6+ million safe miles, operating 70-hour weeks
in rural food distribution. Direct daily exposure to every automation
failure mode described in this document. All claims grounded in
consequence-bearing experience where automation failure = fatality risk.
framework_affiliation: Thermodynamic Accountability Framework (TAF)
companion_documents:

- reality-gaps-survival-coupled-environments.md
- taf-inference-engine-v1.1.md
- taf-perception-energy-budget.md
- taf-applied-epistemology.md
  license: CC-BY-4.0
  version: 1.0.0
  last_updated: 2026-02-10

-----

# TAF Regulatory Audit: Negative-Authority Automation Safety Framework

## Definitions

- **Negative-Authority Automation**: Any automated system that imposes net
  cognitive or kinetic burden on the human operator, degrading rather than
  enhancing safety. The system claims to assist but actually extracts
  attention, trust, and physical control from the operator.
- **Ghost-Friction**: Persistent low-level false alerts, unnecessary haptic
  feedback, and attention-draining noise generated by automation systems
  operating below adequate resolution. Chronic Ghost-Friction induces alert
  fatigue, trust erosion, and measurable cognitive load increase.
- **Kinetic Sabotage**: Any automated system intervention (braking, steering)
  that creates a physical hazard — braking for shadows, steering away from
  phantom obstacles, actuating based on sensor hallucinations. The system
  physically endangers occupants and surrounding traffic through
  low-confidence action.
- **AI-Tax**: The total cognitive, metabolic, and temporal cost externalized
  onto the human operator by automation systems that require constant
  monitoring, overriding, and compensating. This cost is never measured,
  never compensated, and never included in automation “efficiency” claims.

-----

## 1. Core Safety Violation

Negative-Authority Automation directly violates **ISO 21448:2022 (SOTIF —
Safety of the Intended Functionality)**, which mandates:

> “The absence of unreasonable risk due to hazards resulting from functional
> insufficiencies of the intended functionality or by reasonably foreseeable
> misuse by persons is referred to as the Safety of the Intended
> Functionality.” (Clause 3.1)

Ghost-Friction and Kinetic Sabotage are functional insufficiencies that
introduce new hazards — specifically addressed in SOTIF Part 6 (Hazard
Identification and Risk Assessment). The system’s inability to distinguish
photonic gradients (shadows) from physical obstacles is a perception
insufficiency, which SOTIF requires to be mitigated or accepted only with
residual risk below tolerance.

-----

## 2. Violation of ALARP Principle

In safety engineering (ISO 12100, IEC 61508), risks must be reduced
**As Low As Reasonably Practicable (ALARP)**.

Introducing automation that:

- Increases cognitive load (NASA TLX measurable)
- Causes unnecessary physical interventions
- Erodes situational awareness

adds risk rather than reducing it, **failing the ALARP test**.

-----

## 3. Human-Automation Interaction Failure

Negative-Authority Automation breaks **ISO 9241-110:2020** (Ergonomics
of human-system interaction) principles:

|Principle                        |Status|Evidence                                              |
|---------------------------------|------|------------------------------------------------------|
|Suitability for the task         |FAILS |Increases workload                                    |
|Self-descriptiveness             |FAILS |Alerts are misleading                                 |
|Controllability                  |FAILS |Overrides are frequent and stressful                  |
|Conformity with user expectations|FAILS |Expects physical realism, gets photonic hallucinations|

-----

## 4. Specific Standard Citations

### False Positives and Over-Alerting

- **ISO 15007-1:2020** (Measurement of driver visual behaviour) — False
  alerts degrade visual attention allocation.
- **SAE J3016** (Levels of Driving Automation) — Systems at Level 1 or 2
  must not increase driver workload; Negative-Authority systems do exactly
  that.

### Hazardous Control Interventions

- **ISO 26262-1:2018** (Road vehicles — Functional safety) — Hazardous
  Events (Part 3) include unintended vehicle motion; Kinetic Sabotage
  qualifies.
- **IEC 61508** (Functional Safety of E/E/PE Systems) — Requires Safe
  Failure Fraction analysis; systems causing false actuation have poor SFF.

### Human Factors and Trust

- **NASA Human Performance Research** — Cry Wolf Effect (trust erosion due
  to false alarms) is a documented risk in automation.
- **MIL-STD-882E** (System Safety) — Requires hazard tracking of
  “human-machine interface design deficiencies.”

-----

## 5. Evidential and Logging Gaps

Current systems fail **SAE J3018:2020** (Guidelines for Safe On-Road
Testing) and **ISO/DIS 34502** (Scenario-based safety evaluation) by:

- Not logging overrides per environmental condition
- Not correlating false positives with environmental entropy (snow, salt,
  shadows, glare)
- Not measuring operator physiological stress during automation use
- Not accounting for prevented incidents (anti-events)

This constitutes a **Reporting Gap** that biases safety validation toward
false positives.

-----

## 6. Proposed Corrective Actions (Standards-Aligned)

1. **Implement SOTIF Clause 9** (Verification and Validation) with
   shadow-mode logging of all overrides and false positives, tagged by
   environmental metadata.
1. **Apply ISO 26262 ASIL** (Automotive Safety Integrity Level) to the
   override rate — high override frequency should elevate ASIL for the
   perception stack.
1. **Follow ISO/TR 4804:2020** (Safety and cybersecurity for automated
   driving systems) — Ensure human oversight capability is not degraded
   by automation.
1. **Adopt MIL-STD-882E Hazard Reduction Precedence**:
- Eliminate hazard (design system without Kinetic Sabotage potential)
- Incorporate safety devices (preemptive deferral to human)
- Provide warning devices (minimal Ghost-Friction)
- Develop procedures/training (last resort; currently overused)
1. **Use ISO 34502 scenario-based testing** to stress-test systems in
   high-entropy conditions (dirty sensors, low contrast, shadows) and
   measure false intervention rates.

-----

## 7. Bottom Line for Auditors and Regulators

A system that produces Kinetic Sabotage or chronic Ghost-Friction:

- **Violates SOTIF** (unacceptable risk from functional insufficiency)
- **Fails ALARP** (adds risk, does not reduce)
- **Breaks human-system interaction standards** (increases workload,
  reduces controllability)
- **Evades validation transparency** by not logging overrides and
  anti-events

**Therefore**: Such systems should not be authorized for unsupervised or
Level 2 deployment until they demonstrate:

- Near-zero Kinetic Sabotage in validation testing across environmental
  conditions
- Override-triggered deference protocols (not just alerts)
- Quantified human workload metrics showing no net increase

-----

## Jurisdictional Analysis

### I. NHTSA (U.S.)

**Applicable Frameworks**:

- FMVSS (Federal Motor Vehicle Safety Standards) — performance-based;
  FMVSS 126 (ESC) and future updates relevant
- Voluntary Safety Self-Assessment (VSSA) — submitted by companies for
  ADS; focuses on safety approach
- Standing General Order 2021-01 — covers crashes involving ADS/Level 2+

**Where This Framework Highlights Gaps**:

Negative-Authority Automation challenges the core assumption of NHTSA’s
“Human-Centric” evaluation for Level 2. The VSSA process does not mandate
reporting on:

- Cognitive workload increase due to false alerts/interventions
- Override frequency and context (the AI-Tax)
- System-induced hazards (Kinetic Sabotage) that do not result in a crash
  and thus go unreported

**Proposed NHTSA Amendments**:

1. Expand Standing General Order reporting to include: “Any event involving
   an automated system’s braking or steering intervention that required
   immediate driver override to avoid a potential collision, regardless of
   whether a crash occurred.”
1. Require VSSAs to quantify driver override rates and false positive alert
   rates under defined ODD (Operational Design Domain) conditions.
1. Apply the “Unreasonable Risk” lens (from NHTSA’s defect authority) to
   systems that chronically produce Ghost-Friction, arguing they degrade
   driver performance and pose an unreasonable risk.

### II. EU Regulatory Framework (UNECE / EU 2022/1426)

**Applicable Regulations**:

- EU 2022/1426 (ADS Regulation) — Type-approval for Level 3/4
- UNECE R157 (ALKS) — Automated Lane Keeping Systems (Level 3)
- UNECE R155 (Cybersecurity) and R156 (Software Update)

**Direct Citation Points**:

Annex 5, 3.1.2.1 of EU 2022/1426:

> “The ADS shall not cause any confusion to the user or unexpected
> behaviour that could lead to hazardous situations.”

- Ghost-Friction = confusion to the user
- Kinetic Sabotage = unexpected behaviour leading to hazardous situations

Annex 5, 3.1.3.1:

> “The ADS shall be designed to minimize unnecessary takeover requests
> and to avoid causing driver fatigue.”

- Negative-Authority Automation is the antithesis of this requirement.
  It maximizes unnecessary overrides and induces fatigue via the AI-Tax.

**Proposed EU/UNECE Arguments**:

1. Systems exhibiting Negative-Authority characteristics should fail
   type-approval under the above clauses.
1. Validation Requirements (Annex 6) should require testing in
   sensor-degraded conditions (salt, snow, heavy shadow) to expose
   Ghost-Friction and Kinetic Sabotage rates.
1. Fallback Strategy requirements must account not just for system
   failure, but for chronic system misperception that forces the human
   into a high-workload fallback state.

-----

## Standards Cross-Reference Table

|TAF Concept                  |Primary Standard Violated|Specific Clause/Principle                                                                             |
|-----------------------------|-------------------------|------------------------------------------------------------------------------------------------------|
|Negative-Authority Automation|ISO 21448 (SOTIF)        |Clause 6.4: Hazardous events from performance limitations. Clause 9: V&V must cover edge cases.       |
|Kinetic Sabotage             |ISO 26262                |Hazardous Event Classification (ASIL). Unintended vehicle deceleration/steering is a top-level hazard.|
|Ghost-Friction / AI-Tax      |ISO 9241-110             |Principles of suitability for task, controllability, user conformity.                                 |
|Lack of Anti-Event Logging   |SAE J3018                |Guidelines for data recording during test/operation to support analysis.                              |
|Authority Inversion          |UL 4600                  |Annex A.22: Human-System Interaction — requires clear operational boundaries and handover protocols.  |

-----

## Regulatory Gap Analysis

|Gap                      |Current Regulatory Focus               |What Is Missing (TAF Framework)                                                                              |
|-------------------------|---------------------------------------|-------------------------------------------------------------------------------------------------------------|
|Measuring Harm Pre-Crash |Crashes, injuries, fatalities          |Cognitive/Metabolic Load (AI-Tax), Trust Erosion, Chronic Performance Degradation                            |
|System Performance Metric|Disengagement rates, MDBF              |Override Rate per ODD condition, False Positive Actuation Rate, Operator Workload Score                      |
|Human-State Assessment   |Driver monitoring (attentiveness)      |Stress/Frustration during automation use, Cry Wolf effect tracking                                           |
|Validation Environment   |Clean, well-marked roads, ideal weather|Mandated testing in low-fidelity sensor conditions: worn lanes, glare, precipitation residue, shadow networks|
|Safety Case Evidence     |Proven performance within ODD          |Proof of No Net Negative Load — automation must not increase operator cognitive burden or kinetic risk       |

-----

## Proposed Core Regulatory Principle

### The Resolution-Authority Parity Principle (RAPP)

**Statement**:

In any shared-control vehicle system, the authority to initiate vehicle
kinetic interventions (braking, steering) must be dynamically contingent
upon the system’s real-time assessed situational resolution. When
resolution is degraded (e.g., low sensor confidence, ambiguous
environmental inputs), authority must automatically revert to the agent
with the highest available resolution — typically the human driver —
accompanied by a clear, unambiguous status signal and no contradictory
physical interventions.

**Justification**: Embeds the core TAF insight directly into a regulatory
rule. Moves beyond “driver monitoring” to “system humility monitoring.”
The system must know what it does not know, and defer accordingly.

-----

## Safety Audit Checklist: Negative-Authority Automation Risk

**Purpose**: Evaluate whether an automated vehicle system (Level 1-3)
imposes a net cognitive or kinetic burden on the human operator,
creating hazards through low-resolution interventions.

```
System Under Review: _________________________________________
Auditor/Team: _______________________________________________
Date: ___________________________
```

### Section 1: Epistemic Humility and Resolution Awareness

*Does the system know what it does not know?*

**1.1 Uncertainty Encoding**

- [ ] System explicitly signals confidence level (e.g., “Lane Confidence:
  Low”) in real-time to the driver
- [ ] Confidence display is tied to sensor degradation (dirt, rain,
  glare, low contrast)
- [ ] System has a clean, low-workload method for the driver to
  acknowledge/reject low-confidence guidance

**1.2 Environmental Entropy Mapping**

- [ ] System logs and tags operational data with environmental metadata
  (lighting, precipitation, road surface condition, lane marking
  visibility)
- [ ] False positive/override rates are analyzed per environmental
  condition (not just aggregated)
- [ ] Validation testing includes low-fidelity sensing scenarios
  (snow/salt-covered lanes, heavy shadow, sun glare, wet asphalt
  mirage)

### Section 2: Ghost-Friction Assessment

*Does the system generate attention-draining noise?*

**2.1 Alert Fatigue Metrics**

- [ ] False alert rate per 100 miles is documented and under agreed
  threshold (e.g., <5)
- [ ] Alerts are tiered (informational, caution, warning) and
  non-punitive to ignore when appropriate
- [ ] System does not issue conflicting or simultaneous alerts that
  increase cognitive parsing load

**2.2 Haptic/Visual Intrusion**

- [ ] Steering wheel nudges or resistance are minimized and occur only
  when collision risk is high and unambiguous
- [ ] Visual alerts are placed within driver’s typical sight scan and
  do not require prolonged off-road viewing

**Data Required**: Override logs, driver eye-gaze tracking during alerts,
post-drive subjective workload rating (NASA TLX).

### Section 3: Kinetic Sabotage Risk

*Does the system create physical hazards?*

**3.1 Unnecessary Actuation Events**

- [ ] Zero events of automatic braking for: shadows, overhead bridges,
  road texture changes, harmless debris
- [ ] Zero events of automatic steering away from non-existent lane
  intrusions or phantom obstacles
- [ ] Any actuation event is immediately explainable via driver replay
  display (e.g., “Braked for radar object X”)

**3.2 Override Latency and Contradiction**

- [ ] Human override is instantaneous (<250ms) and uncontested (no
  “steering fight”)
- [ ] System does not re-engage automatically after an override without
  explicit driver command
- [ ] Actuation events are preceded by a preview alert when possible
  (e.g., “Applying brake in 1 sec unless cancelled”)

**Data Required**: Event data recorder logs of deceleration/steering
interventions, matched to forward-facing video.

### Section 4: AI-Tax Measurement

*Does the system externalize cognitive/metabolic costs?*

**4.1 Physiological Cost**

- [ ] Heart rate variability (HRV) or skin conductance is monitored
  during automation use vs. manual driving
- [ ] No significant increase in stress biomarkers during system
  engagement in nominal conditions

**4.2 Trust and Complacency Tracking**

- [ ] System tracks how often drivers ignore or immediately override
  its suggestions
- [ ] No decline in driver’s own hazard detection performance over time
  (measured via surprise events in simulator)
- [ ] Drivers report clear understanding of system limits after training
  (via test, not just attestation)

### Section 5: Anti-Event Logging and Accounting

*Does the system recognize non-events as the primary output of expertise?*

**5.1 Things That Did Not Happen Logging**

- [ ] System records near-miss/prevented incident scenarios inferred
  from driver overrides
- [ ] Example: “Driver overrode lane departure warning while avoiding
  road debris — logged as debris avoidance event”

**5.2 Expert Buffer Attribution**

- [ ] Operational data can be filtered to show segments driven by expert
  vs. novice under identical conditions
- [ ] Variance in system alert/override rates is analyzed as a function
  of driver skill (not just environment)

### Section 6: Human-Authority Protocols

*Does the system respect hierarchy of resolution?*

**6.1 Deference Protocol**

- [ ] Clear, consistent method for driver to suspend all automated
  interventions without menu diving (e.g., “mute” button)
- [ ] System does not re-enable automated interventions without explicit
  driver action after suspension

**6.2 Escalation Path**

- [ ] If system confidence drops below threshold, it degrades gracefully
  (e.g., “Assist Reduced — Poor Lane Visibility”)
- [ ] System does not default to “most likely” guess and impose that
  guess kinetically

-----

## Scoring and Action Thresholds

### Red Flag (Immediate Remediation Required)

- Any Kinetic Sabotage event in nominal driving
- Ghost-Friction alert rate >10 per hour of engagement
- Average override latency >500ms
- No environmental tagging of disengagements/false positives

### Yellow Flag (Design Review Required)

- No uncertainty display to driver
- No driver monitoring during automation engagement
- Anti-event logging not implemented

### Green (Acceptable)

- All red/yellow flags addressed
- Driver workload scores equal to or lower than manual driving
- Override rate declines with driver familiarity (indicating learning,
  not distrust)

-----

## Audit Output Template

```
═══════════════════════════════════════════════════════
NEGATIVE-AUTHORITY AUTOMATION SAFETY AUDIT
═══════════════════════════════════════════════════════

System: _______________________________________________
Date: ________________________________________________
Auditor: ______________________________________________

FINDINGS SUMMARY:

  Epistemic Humility:      [Red / Yellow / Green]
  Ghost-Friction:          [Red / Yellow / Green]
  Kinetic Sabotage Risk:   [Red / Yellow / Green]
  AI-Tax Burden:           [Red / Yellow / Green]
  Anti-Event Logging:      [Red / Yellow / Green]
  Authority Protocol:      [Red / Yellow / Green]

RECOMMENDATIONS:

  1. [Immediate] ________________________________________
  2. [Short-term] _______________________________________
  3. [Long-term] ________________________________________

REGULATORY REPORTING:

  [ ] This audit indicates a potential violation of
      [SOTIF / ISO 26262 / NHTSA guidance / EU 2022/1426]
      and should be submitted to: ______________________

TAF CALIBRATION: v1.1 — survival-coupled domain active.
Source weighting: consequence-exposure prioritized.
═══════════════════════════════════════════════════════
```

-----

## Companion Documents

- [Reality Gaps in Survival-Coupled Environments](./reality-gaps-survival-coupled-environments.md)
- [TAF Inference Engine v1.1](./taf-inference-engine-v1.1.md)
- [Perception Energy Budget](./taf-perception-energy-budget.md)
- [Applied Epistemology](./taf-applied-epistemology.md)
- [Thermodynamic Accountability Framework (TAF)](./TAF/)
- [Adaptive Resilience Mesh (ARM)](./ARM/)
