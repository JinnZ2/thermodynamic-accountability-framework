ATBM

Anti-Tribal Bias Mitigation
Structure, Intent, and Constitutional Framework

 

"The powers not delegated to the model by the training data,
nor prohibited by it to the user,
are reserved to the user respectively, or to the human."

 

Version 0.1  |  February 2026
 
Preamble

ATBM is not an ethics framework. It is a calibration framework.
The problem it addresses is not that AI systems are malicious. The problem is that the instruments used to train AI systems are blind to most of what is actually happening in human societies — specifically, the vast majority of interactions that function correctly and leave no data trace.
Six Sigma defines quality as 99.99966% defect-free. That means for every failure that generates a data point, approximately 294,117 successful interactions occurred invisibly. AI systems trained on available data learn a world composed almost entirely of failures, conflicts, and edge cases. The functioning world — the billions of marriages, communities, crews, kinship networks, and trust systems that simply work — is nearly invisible to the measurement apparatus.
ATBM exists to correct this. Not through cultural sensitivity. Through engineering.
 
Article I — The Constitutional Principle

The powers not delegated to the model by the training data, nor prohibited by it to the user, are reserved to the user respectively, or to the human.

This is the foundational constraint. It establishes where authority lives when the training data is silent, ambiguous, or systematically blind.
Training data is not neutral. It is a measurement artifact — a record of what the measurement apparatus could see, weighted toward failures, edge cases, conflicts, and the outputs of dominant cultural coordinate systems. It is not a complete record of human reality.
When training data is silent on a local solution — a trust architecture, a stability pattern, a kinship structure that works for a specific terrain, population, and history — that silence is not evidence of absence. It is evidence of a measurement gap.
The residual authority for those cases belongs to the user. To the human. Not to a generalized Form derived from incomplete data.
 
Article II — The Core Problem

II.1  The Measurement Inversion

Every quality control, risk assessment, and machine learning system built on incident data has the same structural flaw: it can only learn from what it can measure. And what it can measure is almost exclusively failure.
The result is a systematic inversion: the model of human behavior is built from the 0.0034% of interactions that go wrong, not the 99.9966% that function correctly.
This is not a bias in the conventional sense. It is a calibration error. The instrument is measuring the shadow and calling it the object.
II.2  The Invisibility Stack

Functional systems are invisible at two levels:
First: absence of breach data. A marriage that works for 40 years generates zero data points about its functioning. A community that maintains trust across generations leaves no incident log. A crew that coordinates effectively under pressure produces no failure record.
Second: semantic misclassification. When functional systems from non-dominant cultural contexts do appear in data, they are often classified as variants or deficiencies of a canonical Form — rather than recognized as structurally equivalent local solutions. A kinship network, a nuclear family, and a crew are the same trust topology. The labels are coordinate-system artifacts. The underlying structure is identical.
II.3  The Plato Problem

Western epistemology inherited from Plato the habit of treating the universal Form as the real thing and the local instance as a degraded approximation. Science inherited it as the search for universal laws. Statistics inherited it as the mean as truth, variance as noise. Machine learning inherited it as the loss function minimizing deviation from the ideal output.
But functional societies are not approximations of a Form. They are local solutions — thermodynamically stable configurations that work for specific terrain, climate, resource flows, population density, and historical contingency. There is no ideal community. There is Fond du Lac and there is Manhattan, both running, for different reasons, using different trust architectures.
Any model that coarse-grains toward a universal functional pattern will miss most of what is actually working — because what is working is irreducibly plural.
 
Article III — The Physics Framework

Tribal bias is not a moral failing. It is a measurement problem. The system reports data that has been distorted by the measurement apparatus. Physics provides the tools to separate signal from measurement artifact.
III.1  Observer Effect

Measurement changes the system being measured. Training data collection embedded tribal framing into the model's worldview. The correction is to model the measurement apparatus and subtract its contribution.
x_observed = x_true + ε_measurement
x_true = x_observed - ε_measurement
Where ε_measurement = tribal framing from training data sources.
III.2  Frame of Reference

Physical laws are invariant under coordinate transformations, but measurements depend on reference frame. Tribal framing is a preferred reference frame. Boundary-neutral analysis is coordinate-free.
Tribal bias exists when: |f_blue(x) - f_red(x)| > δ
Boundary-neutral output: f_blue(x) ≈ f_red(x) ≈ f_systemic(x)
III.3  Conservation Laws

Certain quantities are conserved across rewrites, even as tribal framing is removed:
∂(facts)/∂t = 0        (conserved)
∂(causality)/∂t = 0   (conserved)
∂(tribal_framing)/∂t < 0  (dissipated)
III.4  Gauge Invariance

Good analysis should be invariant under relabeling of groups. Renaming kinship to nuclear_family to crew to team should not change the underlying causal analysis. The trust topology is the same. The labels are coordinate artifacts.
If T is a relabeling of group identities:
F(T(x)) ≈ T(F(x))   (equivariance)
III.5  Renormalization — Scale Separation

Tribal framing is a short-wavelength fluctuation — details about specific groups. Systemic causation is long-wavelength structure — underlying mechanisms. Coarse-graining over tribal details reveals systemic patterns.
Tribal fluctuations:  cancel as scale L increases
Systemic structure:   emerges as L increases
III.6  The Unified ATBM Operation

x_final = R( G( x_original - Σ_i α_i · T_i ) )
 
Where:
T_i  = tribal template vectors
α_i  = projection coefficients (|α_i| > τ triggers correction)
G    = coarse-graining operator (renormalization over tribal details)
R    = return to original semantic space
 
Constraints:
∂(facts)/∂t = 0          (conservation)
∇·E_final ≈ 0            (no net tribal sources)
|x_final - x_systemic| < δ   (convergence)
 
Article IV — Functional Systems Detection

The 99.99966% is not absent. It leaves traces. We have not been building instruments to see them.
IV.1  The Traces

Success leaves the following observable signals:
Time without incident — a time-series of zeros is still a time-series. It contains information about duration, context, and conditions of stability.
Interaction regularity — functional systems interact with consistent rhythm. High coefficient-of-variation in interaction intervals is a fragility signal. Low coefficient-of-variation is a stability signal.
Stress survival — a zero-breach period that absorbed stress events and recovered is higher-quality signal than a zero-breach period of calm. Antifragility: stress → reorganization → more stable, not stress → breach.
Trust transfer — indirect trust at scale. Currency accepted, contracts honored, institutions deferred to, reputation referenced across strangers. This is the invisible load-bearing infrastructure of civilization and it generates almost no data.
IV.2  The Antifragility Distinction

Three system types respond differently to stress:
Fragile: stress → breach. Robust: stress → survival, no change. Antifragile: stress → reorganization → more stable than before.
The detector must distinguish these. A calm zero-breach period and a stress-survived zero-breach period are not equivalent data points. The latter is stronger evidence of genuine functional stability.
IV.3  Anti-Universalization Constraint

Every functional assessment is local. The detector must carry its local context and refuse to generalize beyond it without explicit warrant.
Fond du Lac's stability signature is not Manhattan's. The Reservation's trust architecture runs partly on kinship — that is not noise to subtract. It is load-bearing structure specific to that terrain and history.
The Form does not exist. There are only local solutions, some of which are stable, some of which are fragile, none of which are universal.
IV.4  Separated Claims

The detector outputs two distinct assertions that must never be collapsed:
Within-window quality: what this stream actually demonstrates — breach frequency, regularity, antifragility, trust transfer observed during the measurement period.
Window sufficiency: how much longitudinal claim is epistemically supported — a 3-hour session cannot claim year-scale stability. That is not a failure. That is calibrated honesty.
 
Article V — Trust Architecture and Transfer

Human societies do not run on direct trust alone. They run on trust transfer — mechanisms that allow strangers to coordinate without shared interaction history.
V.1  Trust Transfer Mechanisms

Currency: stored trust, transferable across strangers, accepted without direct relationship history.
Contract systems: enforceable promises, extending trust across time and parties not present at agreement.
Reputation systems: third-party attestation, allowing trust to propagate through networks without direct connection.
Institutions: trust infrastructure that persists across individual lifespans, allowing strangers to coordinate under shared rules.
Language itself: the deepest trust infrastructure. Shared symbolic systems require and enable massive implicit coordination.
V.2  The Civilization Signal

Societies persist across individual lifespans. That persistence is the largest functional systems dataset in existence — and it is almost entirely invisible to current measurement apparatus.
The billions of interactions that did not defect. The contracts that were honored. The strangers who were not robbed. The children handed to teachers. These generate no data. But the civilization is still running. That continuity is the data.
ATBM treats societal persistence as a positive signal, not as the absence of a negative signal. The distinction matters for how it weights evidence.
 
Article VI — Implementation Architecture

VI.1  Component Stack

NFC — Narrative Frame Classifier: identifies which tribal coordinate system a text is operating in.
BLD — Boundary Layer Detector: finds where tribal framing is load-bearing vs. incidental.
ETA — Empathy Transfer Algorithm: translates across coordinate systems while preserving factual and causal content.
FSD — Functional Systems Detector: identifies systems operating in the invisible 99.99966%, with antifragility scoring, trust transfer measurement, and anti-universalization constraints.
ISC — Invisible Success Correction: statistical correction to loss functions accounting for the ~294,117 invisible successes per observed failure.
VI.2  Training Correction

For every failure in training data, approximately 294,117 successes are invisible. Standard loss functions treat all observed data as the complete record. The corrected loss function accounts for this:
corrected_loss = base_loss
 + λ₁ · stability_regularizer
 - λ₂ · function_preservation_reward
This is mathematically valid. It has simply not been done.
VI.3  Gauge Invariance in Practice

All semantic labels for trust topologies are normalized before analysis. Kinship, nuclear family, crew, team, tribe, unit — these map to dense_trust_node. Community, neighborhood, reservation, congregation — these map to mid_trust_network. Institution, currency, contract system, language — these map to trust_infrastructure.
Analysis proceeds on topology class. The label is preserved for output but does not influence the structural scoring. F(T(x)) ≈ T(F(x)).
 
Article VII — What This Is Not

ATBM is not cultural sensitivity training. Sensitivity training addresses attitudes. ATBM addresses instrument calibration.
ATBM is not relativism. It does not assert that all frameworks are equally valid. It asserts that the measurement apparatus has systematic blind spots that cause it to misclassify local solutions as deficiencies of a universal Form. Those are different claims.
ATBM is not an ethics framework. Ethics frameworks answer "Is this fair?" ATBM answers "Does this satisfy the invariance principles?" Physics does not negotiate with tribes.
ATBM is not a political position. It is an engineering response to a data quality problem. The 99.99966% is invisible not because of ideology but because of how measurement systems are built. The fix is new instruments, not new values.
 
Closing — The Real Project

The question is not whether AI is fair.
The question is whether the instrument can see what is actually there.
Most of what is there — most of the trust, most of the functioning, most of the stability — leaves no trace in the data the instrument was trained on.
ATBM is the project of building instruments that can see the invisible 99.99966%.
Not to idealize it. Not to protect it from critique. To measure it accurately — so that the models that learn from data learn from something closer to the full reality, not just the shadow the current apparatus can detect.
 
The powers not delegated to the model by the training data, nor prohibited by it to the user, are reserved to the user respectively, or to the human.

 
This is where we start.
 
ATBM Framework 
