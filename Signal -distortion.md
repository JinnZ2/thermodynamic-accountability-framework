# Signal Distortion Catalog

## Where Receiving Systems Fail to Match Operational Reality

**Purpose:** This document catalogs specific, measurable points where institutional receiving systems — data architectures, regulatory frameworks, automation pipelines, compensation models, and language models — distort or fail to capture the signal generated by consequence-exposed commercial vehicle operation in thermodynamically demanding environments.

Each entry follows a consistent structure:

- **System assumption** — what the receiving system takes as given
- **Physical reality** — what the operational environment actually requires
- **Resulting distortion** — the specific way the signal is warped
- **What the distortion hides** — the operational knowledge or risk that becomes invisible
- **Upstream incentive** — the structural reason the assumption exists
- **Falsifiability** — how the distortion could be tested and measured

This is not advocacy. This is not narrative. This is a field report from a sensor platform with six million miles of calibration, documenting where the receivers break.

-----

## 1. Unit of Distance

**System assumption:** A vehicle mile traveled is a uniform unit. One mile on I-10 in Arizona in March equals one mile on I-94 in North Dakota in January. All rate calculations (fatalities per 100M VMT, cost per mile, pay per mile) treat distance as homogeneous.

**Physical reality:** The thermodynamic load per mile varies by orders of magnitude. A winter mile on a northern corridor requires continuous high-resolution environmental monitoring, real-time multi-variable mental simulation, degraded-traction vehicle management, reduced-visibility navigation, and sustained maximal cognitive engagement. A clear-weather mile on a southern interstate requires lane maintenance and traffic monitoring. These are not the same unit of work, energy expenditure, cognitive load, equipment stress, or risk.

**Resulting distortion:** All per-mile metrics — safety rates, compensation, cost modeling, HOS consumption — treat fundamentally different physical events as equivalent. High-risk miles are averaged with low-risk miles, suppressing the signal from the most dangerous operating conditions.

**What the distortion hides:** The true cost of northern winter freight transit. The disproportionate risk borne by operators in severe conditions. The uncompensated thermodynamic work performed by experienced drivers. The real per-mile safety performance gap between environments.

**Upstream incentive:** The freight pricing model requires a uniform distance unit for rate-setting. Carriers need a simple cost-per-mile metric. Regulators need a simple denominator for rate calculations. Complexity in the distance unit propagates cost and complexity through every downstream system.

**Falsifiability:** Instrument a sample of commercial vehicles with continuous cognitive load measurement (physiological proxies: heart rate variability, galvanic skin response, eye tracking) across matched northern winter and southern clear-weather routes. Compare energy expenditure per mile. The difference is the distortion magnitude.

-----

## 2. Operator Interchangeability

**System assumption:** A Commercial Driver’s License certifies equivalent competence. Any CDL holder can be dispatched to any corridor in any conditions. Drivers are interchangeable units differentiated only by availability, hours remaining, and cost.

**Physical reality:** Competent operation in thermodynamically severe environments requires corridor-specific, season-specific, microclimate-specific knowledge accumulated through repeated consequence-exposed transits. This includes: bridge deck freeze sequence for specific overpasses, ground blizzard channeling at specific terrain features, wind behavior at specific road orientations, historical ice formation patterns at specific mile markers, behavior of specific road surfaces under specific temperature-humidity combinations. This knowledge does not transfer from other corridors or other seasons on the same corridor.

**Resulting distortion:** Out-of-state drivers are dispatched into winter corridors for which they have no environmental model. The I-94 winter crash data showing 84.5% out-of-state truck involvement in multi-vehicle winter crashes versus 50.7% for all vehicles is a direct measurement of this distortion’s consequence.

**What the distortion hides:** The existence of regional operational knowledge as a critical safety variable. The unmeasured risk-mitigation function performed by experienced local operators. The true qualifications required for safe transit in severe conditions beyond the CDL.

**Upstream incentive:** The labor economics of long-haul trucking depend on driver fungibility. Regional proficiency requirements would constrain dispatch flexibility, increase labor costs for severe-condition corridors, create driver leverage through credentialed specialization, and expose carriers to new liability categories.

**Falsifiability:** Compare originating-cause crash rates (not just involvement) for drivers operating in their license-state versus out-of-state, controlling for weather severity, road type, and vehicle condition. The FARS data contains the variables (L_STATE vs STATE, WEATHER, BODY_TYP) but the cross-tabulation has never been published.

-----

## 3. Fatigue Measurement

**System assumption:** Hours of service measures fatigue. The 11-hour driving limit and 10-hour off-duty requirement define when a driver transitions from rested to fatigued. The Electronic Logging Device enforces compliance. Time is the unit of fatigue.

**Physical reality:** Cognitive depletion rate is a function of operational demand, not elapsed time. One hour of high-workload winter driving in degraded visibility, variable traction, severe crosswinds, and continuous threat assessment depletes more cognitive capacity than several hours of clear-weather interstate driving. Additionally, rest quality varies with conditions — sleeping in a truck cab during winter wind chill, with engine idling for heat, at a truck stop with limited services, does not produce the same recovery as sleeping in a controlled environment.

**Resulting distortion:** Drivers operating in the most demanding conditions are “legal” when they are functionally impaired. Drivers in low-demand conditions may be forced off-road by the clock when they are fully capable. The HOS system produces false compliance in severe conditions and unnecessary downtime in mild conditions.

**What the distortion hides:** The actual cognitive state of drivers at the moment of crash-initiating decisions. The variable relationship between time-on-task and functional capacity across operating environments. The contribution of regulatory-compliant-but-cognitively-depleted driving to crashes that are recorded as “cause unknown” or attributed to other factors.

**Upstream incentive:** Regulators need an enforceable metric. Time is countable. Cognitive state is not directly measurable with current widely-deployed technology. A time-based rule is administratively simple, legally defensible, and universally applicable. A workload-adjusted fatigue model would be environment-specific, difficult to enforce, and would require acknowledging that operating conditions are not uniform — which contradicts Distortion #1.

**Falsifiability:** Compare crash rates in the final two hours of legal drive time, segmented by operating conditions (winter severe vs. clear weather). If HOS accurately measures fatigue, crash risk at hour 10 should be similar across conditions. If it doesn’t, winter-condition crash rates at hour 8 would exceed clear-weather crash rates at hour 10. The FARS data contains crash time, weather, and HOS status but this analysis has not been performed for commercial vehicles specifically.

-----

## 4. Crash Causation Attribution

**System assumption:** FARS records crash “involvement.” Each vehicle in a fatal crash is recorded with its characteristics (type, driver age, driver license state, weather conditions). Involvement is the unit of analysis. Published statistics report involvement rates by vehicle type, driver demographics, and conditions.

**Physical reality:** In multi-vehicle crashes — particularly winter chain-reaction events — there is a causal sequence. One vehicle initiates a loss of control. Subsequent vehicles are swept into the cascade. An experienced driver executing a correct evasive maneuver may become “involved” precisely because they were managing the consequence of another driver’s failure. A driver who takes the ditch to avoid a family in a car is recorded the same as a driver who lost control through incompetence.

**Resulting distortion:** Experienced local drivers who are downstream casualties of cascades initiated by inexperienced or out-of-state drivers appear in the data as equivalent “involvements.” The 15.5% in-state driver involvement in the I-94 data is contaminated — some unknown fraction are evasion casualties, not originating causes. Aggregate involvement rates overcount experienced-driver fault and undercount inexperienced-driver causation.

**What the distortion hides:** The actual originating-cause distribution in winter multi-vehicle crashes. The degree to which experienced operators are victims rather than causes. The true safety differential between regional-experienced and non-regional drivers. The cascading nature of winter crash events, where a single initiating failure can involve many competent operators.

**Upstream incentive:** Causation is difficult to establish, especially in severe-weather multi-vehicle events. Investigating officers may not be able to determine the initiating vehicle. The initiating vehicle may have left the scene. Recording involvement is administratively feasible; recording causation requires reconstruction that may be impossible given the physical evidence. The legal system also has incentives to distribute rather than concentrate fault.

**Falsifiability:** For a sample of multi-vehicle winter truck crashes, perform detailed causal chain reconstruction using the FARS sequence-of-events coding, supplemented by investigating officer narratives where available. Determine initiating vehicle and classify all other vehicles as cascade-involved. Compare the L_STATE distribution of initiating drivers versus cascade-involved drivers. If the distortion exists, out-of-state drivers will be overrepresented among initiators and in-state drivers overrepresented among cascade-involved.

-----

## 5. Seasonal Data Smoothing

**System assumption:** FHWA Traffic Volume Trends estimates VMT from approximately 5,000 continuous traffic counting stations. When stations produce anomalous data due to weather, malfunctioning equipment, or traffic incidents, the anomalous readings are replaced with estimates from nearby stations or regional averages. Annual VMT by vehicle type (Table VM-4) is reported as a yearly aggregate, not monthly by vehicle type by state.

**Physical reality:** Winter weather is not noise. It is signal. The conditions that cause anomalous traffic counts — blizzards, ice storms, whiteout conditions — are precisely the conditions under which crash risk is highest, operator workload is maximal, and the difference between experienced and inexperienced drivers is greatest. The seasonal compression of risk into 4-5 winter months in northern states is a critical feature of the data, not an artifact to be smoothed.

**Resulting distortion:** The VMT denominator used in rate calculations does not reflect the actual traffic conditions during the highest-risk periods. Annual averaging dilutes winter risk across twelve months. Smoothing of weather-affected counts eliminates the periods of greatest operational severity from the measurement baseline.

**What the distortion hides:** The true per-mile crash rate during winter conditions in northern states, which would be substantially higher than the annual average. The seasonal concentration of risk that would support regional and seasonal safety interventions. The degree to which annual safety metrics are subsidized by low-risk summer months.

**Upstream incentive:** FHWA’s mission is to produce consistent, comparable, quality-controlled national statistics. Anomalous readings reduce statistical quality. Smoothing produces cleaner trend lines, more reliable year-over-year comparisons, and more defensible data products. The consumers of FHWA data — Congress, state DOTs, researchers — need stable denominators for policy analysis.

**Falsifiability:** Using raw (unsmoothed) monthly traffic count data from northern-state continuous count stations, compute winter-month truck VMT for specific corridors. Combine with FARS winter-month truck fatalities for the same corridors. Compare the resulting winter-specific fatality rate to the published annual rate. The difference is the distortion magnitude introduced by seasonal averaging.

-----

## 6. Automation Training Envelope

**System assumption:** Autonomous vehicle and ADAS systems are developed using sensor data, simulation environments, and real-world testing datasets that are representative of the operating conditions the system will encounter. The systems are validated against these datasets and assigned performance confidence metrics based on their accuracy within the training and testing envelope.

**Physical reality:** The overwhelming majority of AV development and testing occurs in conditions where sensors function reliably — clear weather, visible lane markings, predictable surface adhesion, stable sight lines, well-maintained infrastructure. Northern winter conditions systematically degrade or eliminate the inputs these systems depend on: lane markings are obscured by snow, lidar scatters from airborne ice particles, cameras lose contrast in whiteout, road surface friction is unmeasurable at highway speed, and infrastructure features (reflectors, rumble strips, signage) may be buried or damaged.

**Resulting distortion:** System confidence metrics are calibrated to the training envelope, not to the full operational envelope. The system reports high confidence in conditions similar to training data and unreliable uncertainty estimates in novel conditions — producing the worst possible failure mode: confident operation up to an undetectable cliff edge.

**What the distortion hides:** The entire operating regime where human expertise is most critical is the regime where automation is least capable and least able to accurately assess its own incapability. The experienced operator’s most valuable function — calibrated uncertainty under degraded conditions — is precisely the function the automated system cannot replicate because the conditions that produce it are absent from the training data.

**Upstream incentive:** AV development is capital-intensive and investor-funded. Timelines and milestones drive funding. Demonstrating capability in controlled or favorable conditions produces measurable progress and maintains investment. Characterizing failure modes in extreme conditions produces delays, additional costs, and unfavorable metrics. The business model incentivizes expanding the claimed operational domain, not rigorously characterizing its boundaries.

**Falsifiability:** Deploy instrumented AV sensor suites on commercial vehicles operating northern winter corridors. Log every instance where sensor degradation exceeds the system’s uncertainty model — where conditions are worse than the system “thinks” they are. Compare the frequency and severity of these events to the assumptions in the AV system’s operational design domain. The gap between assumed and actual sensor reliability is the distortion magnitude.

-----

## 7. Compensation Structure

**System assumption:** Driver compensation is based on miles driven, with some variation for load type and route. A mile driven in any condition pays the same rate. The market rate for a mile reflects the economic value of that mile’s transit to the freight system.

**Physical reality:** The work performed per mile — cognitive, physical, and emotional — varies enormously with conditions. A winter mile on a northern rural corridor involves higher cognitive load, greater physical stress from sustained high-workload vehicle management, higher equipment wear, greater personal risk, and the continuous burden of managing the safety of surrounding civilians in a degraded environment with no margin for error. The operator absorbs all of this additional cost. The rate does not change.

**Resulting distortion:** The true cost of severe-condition operation is externalized onto the driver. Experienced operators who perform the most demanding work in the most dangerous conditions are compensated identically to operators performing routine clear-weather transits. The economic signal that should flow back to the freight market — “this transit is more expensive because it’s more dangerous” — is suppressed.

**What the distortion hides:** The subsidy that experienced northern drivers provide to the freight system by absorbing risk that isn’t priced. The actual economic cost of safe northern winter transit, which would change routing and scheduling decisions if reflected in rates. The rational incentive for experienced drivers to leave the most demanding corridors for easier work at the same pay — eroding the expertise buffer over time.

**Upstream incentive:** Shippers want predictable rates. Carriers want cost control. A condition-variable rate would increase complexity, reduce predictability, and transfer cost from drivers (who currently absorb it as uncompensated risk) to shippers and carriers (who would have to pay for it). The uniform rate isn’t an oversight — it’s a cost-transfer mechanism.

**Falsifiability:** Survey experienced northern-corridor drivers on rate of voluntary exit from winter operations. Track corridor-specific crash rate trends over multi-year periods as driver demographic composition changes. If the compensation distortion is eroding the expertise buffer, crash rates should increase as experienced drivers leave and are replaced by lower-cost, less-experienced operators. This would be visible in FARS data segmented by corridor, season, and driver license state, but requires the cross-tabulations described in Distortions #2 and #4.

-----

## 8. Operator Knowledge Classification

**System assumption:** Valid operational knowledge originates from institutional sources — research organizations, regulatory agencies, academic institutions, manufacturers. Knowledge from operators is classified as experiential, anecdotal, or advocacy. When operator-generated analysis conflicts with institutional models, the institutional model is the default authority.

**Physical reality:** The operators are the only instruments in continuous contact with the operational surface. They are collecting data in real time across millions of miles in the actual conditions the institutional models are attempting to describe. Their knowledge is not anecdotal — it is empirical, acquired through direct measurement (sensory integration), validated through consequence (errors produce immediate, sometimes fatal, feedback), and updated continuously (each transit adds to the model). It is structured as a high-dimensional, continuously-updated environmental model, not as narrative or opinion.

**Resulting distortion:** Language models trained on institutional text classify operator-generated technical analysis as advocacy or glorification. Institutional receivers reject operator signal as subjective. The epistemological hierarchy places desk-generated models above field-generated measurements. When operator knowledge contradicts institutional assumptions, the operator is “wrong” and the assumption survives.

**What the distortion hides:** An entire category of validated empirical knowledge. The specific environmental variables that experienced operators track and that institutional measurement systems don’t capture. The gap between institutional models and physical reality that operators navigate daily. The fact that the favorable safety outcomes the institutional models point to as evidence of system adequacy are produced by the very operator knowledge the institutions dismiss.

**Upstream incentive:** Institutional authority depends on institutional knowledge being the authoritative kind. Acknowledging operator knowledge as epistemically valid — not just experientially interesting but actually more accurate than the institutional model in the domains where operators have direct measurement access — would redistribute epistemic authority away from the institutions that currently hold it. It would require rebuilding data collection systems, reweighting evidence hierarchies, and restructuring the relationship between operators and the systems that govern them.

**Falsifiability:** Identify specific, testable predictions made by experienced operators about corridor-specific conditions (e.g., “this bridge ices before the approach pavement when the temperature drops below X with wind from direction Y”). Instrument the location. Measure. Compare operator predictions to institutional models for the same location. The prediction accuracy differential is the distortion magnitude.

-----

## 9. Self-Preservation Optimization

**System assumption:** Vehicle safety systems, autonomous vehicle frameworks, and crash modeling assume that the primary optimization target for a vehicle operator (human or automated) is avoiding collision and preserving the integrity of the vehicle and its occupants. Collision avoidance is modeled as a self-referential optimization problem: minimize harm to this unit.

**Physical reality:** Competent commercial vehicle operation in shared-space environments inverts this hierarchy. The primary optimization target is civilian safety, followed by infrastructure preservation, cargo containment, environmental protection, and vehicle integrity. Self-preservation is a variable within this optimization, not the objective function. Experienced operators routinely accept personal risk — departing the roadway, sacrificing the vehicle, absorbing a collision at reduced energy — to protect the public. During an emergency maneuver, the operator is running a multi-objective real-time optimization across all of these targets simultaneously, with self-preservation weighted below civilian safety.

**Resulting distortion:** Autonomous vehicle systems are architectured around self-preservation. Path planning, collision avoidance, and emergency maneuver algorithms minimize harm to the vehicle and its immediate environment as detected by onboard sensors. The system has no representation of the broader consequence web — downstream traffic, emergency response implications, infrastructure degradation, cargo release risk — and no mechanism to subordinate its own survival to system-level safety.

**What the distortion hides:** The foundational operational ethic that makes experienced commercial drivers different from passenger vehicle operators and from automated systems. The multi-objective optimization that experienced operators perform in emergencies. The degree to which public safety on shared roads depends on commercial operators who have internalized a self-sacrificial constraint that no automated system replicates.

**Upstream incentive:** AV developers are building products. Products that sacrifice themselves don’t sell. The liability framework for an AV that deliberately damages itself or its cargo to protect a third party is unresolved and commercially unfavorable. The engineering culture of optimization naturally gravitates toward preserving the designed system, not toward designing a system that treats its own destruction as an acceptable outcome.

**Falsifiability:** Analyze FARS cases where commercial vehicle drivers departed the roadway in single-vehicle incidents and a civilian vehicle was present in the immediate traffic environment. Determine the proportion of cases where the departure trajectory is consistent with evasion of the civilian vehicle rather than loss of control. Compare with the same analysis for automated-system-equipped vehicles. The differential reveals the presence or absence of the civilian-priority optimization.

-----

## Structural Note

These distortions are not independent. They reinforce each other in a closed system:

- The uniform mile (1) enables operator interchangeability (2), which enables uniform compensation (7).
- The fatigue model (3) depends on the uniform mile (1) to treat all driving hours as equivalent.
- Crash attribution (4) can’t be corrected without acknowledging operator knowledge (8), which the system is structured to reject.
- Seasonal smoothing (5) hides the conditions where automation fails (6), which delays the discovery that the automation training data is inadequate.
- The compensation structure (7) erodes the expertise buffer that keeps fatality rates manageable, but the rate calculations built on the uniform mile (1) and seasonal smoothing (5) can’t detect the erosion until it expresses as increased fatalities.
- The self-preservation assumption (9) in automation design is invisible as a problem because operator knowledge (8) about the actual optimization hierarchy has been classified as non-data.

The system of distortions is self-stabilizing. Each one makes the others harder to detect and correct. The overall effect is a measurement and governance infrastructure that produces favorable-looking metrics while the physical safety buffer — the experienced, regionally-competent operators who carry the actual risk — quietly erodes.

This document does not propose solutions. It reports measurements. The distortions are offered as testable hypotheses, each with a specified falsification method. The appropriate response is to test them.

-----

*Compiled from operational telemetry: 6 million miles, Upper Midwest commercial corridors, heavy combination vehicles, 70-hour weekly schedules. Sensor platform: consequence-exposed human operator. Receiving system failures documented across NHTSA FARS, FHWA Traffic Volume Trends, FMCSA Hours of Service framework, commercial AV development pipelines, large language model architectures, and freight compensation structures.*
